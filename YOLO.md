### YOLOv1（2016）

- 将图像划分为7x7的网格，如果某个物体的中心落在这个网格中，那么这个网格就负责预测这个物体
- 没有anchor的概念
- 然后每个网格预测两个边框，即预测出7x7x2个窗口
- 在VOC数据集上，预测位置（xywh）+置信度以及类别，所以输出为7x7x(5+5+20)
-  根据阈值使用nms过滤冗余的
-  但是每个格子只会选择出iou最高的那个目标，所以如果每个格子包含多个物体，就只能检测出其中一个
- 输出层为全连接层
- 损失函数：三个损失函数都使用误差平方和
- 群体小目标检测效果差
- 出现新尺寸的目标时，效果差，原因是没有使用anchor导致定位不准确

### YOLOv2 （2017）

- 也叫YOLO9000，因为使用了VOC数据集以及Imagenet数据集联合训练，可以检测9000个类别，使用Darknet19骨架训练
- 使用了Anchor，基于Kmeans的聚类方法自动提取先验框的信息，可根据不同的数据集设置Anchor
- 使用了更高的分辨率，训练backbone的时候从224x224到448x448
- 多尺度训练，每迭代10个batch，随机更换尺寸320、352...608，都为32的倍数
- 使用了Passthrough，类似Pixel-shuffle，融合高层和低层的信息，更好检测小物体
- 每个Anchor预测5个Boundingbox，所以输出5x(5+20)，坐标、置信度+类别
- 采用了BN层，并且去掉了全连接层，最后添加了3个1024x3x3维度的卷积层，最后再使用1x1卷积来预测目标，输出的个数为上面的125个

### YOLOv3 （2018）

![img](imgs/2018100917221176.jpg)

- Darknet-53，类似Resnet结构,堆叠残差结构，没有最大池化层，下采样通过两个步长的卷积操作完成，全部由卷积搭建而成（全卷积网络）
- 基本部件：卷积+BN+Leaky relu、残差结构res_unit
- 多尺度预测，采用类似FPN融合的方式，在三个不同尺寸大小的特征层上预测不同尺度信息，每个特征层三种尺度，所以最后为9个，从YOLOv2的5个变成9个
- 大目标输出维度：13x13x255，其中255=（80+5）×3；中目标输出维度：26×26×255；小目标输出维度：52×52×255
- 正负样本匹配：如何重合度高但不是最高的，则依旧抛弃。只选取重合度最高的
- 损失函数：置信度损失使用的是BCE、类别损失也是使用BCE、定位损失使用差值平方损失
- 分类器损失采用binary cross-entropy loss(二分类交叉损失熵) 而不是使用softmax，因为有的目标可能存在重叠的类别标签（多标签分类）：SUV又是车又是SUV，而softmax只会输出最大的类别。

### SPP

> 受spp-net的启发而来：Spatial Pyramid Pooling，空间金字塔池化结构

- mosaic图像增强：四张图像拼接在一起
  - 增加数据多样性
  - 增加目标个数
  - BN能一次性统计多张图片的参数
  - 节省显存，在不增加batchsize的情况下，起到了增加batchsize的作用
- 在第一个预测特征层前加入SPP模块
  - 四个分支：输入直接接输出、5x5最大池化、9x9最大池化、13x13最大池化
  - 池化前padding操作
  - 因为池化的步长为1，所以特征层的宽高不变
  - 将宽高、深度一致的特征图concat拼接
- 背景
  - 在一般的CNN网络结构中，最后的分类层通常是由全连接组成，而全连接有个特点，那就是它的特征数是固定的，这就导致了图片在输入网络的时候，大小必须是固定的，但是在实际情况中，图片大小是多种多样的，如果不能满足网络的输入，图片将无法在网络中进行前向运算，所以为了得到固定尺寸的图片，必须对图片进行裁剪或者变形拉伸等，这样就很可能会导致图像失真，从而影响最终的精度，而我们希望网络能够保持原图大小的输入，得到最大的精度
  - 有效避免了对图像区域剪裁、缩放操作导致的图像失真等问题
  - 解决了卷积神经网络对图像重复特征提取的问题，大大提高了产生候选框的速度，且节省了计算成本

### YOLOv4

> - **Bag of freebies**
>
>   采用一些方法使模型有更高的准确度但是不增加模型的复杂度和模型的推理代价
>
> - **Bag of specials**
>
>   指 plugin module 或后置方法以些许推理代价的增加换取模型准确率的提升。

- 骨架：CSPDarknet53
  - 直接用两路的1x1卷积将输入特征进行变换。将全部的输入特征利用两路1x1进行transition，比直接划分通道能够进一步提高特征的重用性，并且在输入到resiudal block之前也确实通道减半，减少了计算量。
- Neck：SPP、PAN
- 头部：与YOLO V3一样

- 骨架中包含的BoF：
  - CutMix
  - 马赛克数据增强
  - DropBlock正则化
  - 类标签平滑
- 骨架中包含的BoS：
  - Mish激活函数
  - CSP
  - 多输入权重残差连接（MiWRC）
- 检测器中包含的BoF：
  - CioU损失
  - CｍBN
    - Cross mini-Batch Normalization
    - CBN的改进版本。它只收集了一个批次中的mini-batches之间的统计数据
  - DropBlock正则化
  - 马赛克数据增强
  - 自对抗（SAT）
    - 它在前后两个阶段上进行操作。在第一阶段，神经网络改变原始图像而不是网络权值。用这种方式，神经网络自己进行对抗训练，改变原始图像，造成图像上没有需要的物体的假象。在第二阶段，神经网络使用常规的方法进行训练，在第一阶段修改之后的图片上进行。
  - 消除grid敏感度
  - 对于一个ground truth使用多个anchor
  - cosine退火算法
  - 优化超参数
  - 训练随机输入图像尺寸。

- 检测器中包含的BoS：
  - Mish激活函数
  - SPP模块
  - SAM模块  
    - 将 SAM 的 spatial-wise 注意力改为 point-wise 注意了机制
  - PAN路径集成模块
    - 将 PAN 中的 shortcut 连接变成 concatenation 连接，
  - DioU-NMS

### YOLOv5

### YOLOX