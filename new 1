# unet（2015）
unet网络是基于fcn网络做改进的，因为网络像U型，所以网络也叫Unet
unet的第一部分是主干特征提取部分，我们可以利用主干部分获得一个又一个的特征层，
这里的特制特征提取部分主要就是堆叠卷积和池化的操作。
通过主干特征提取网络，可以获得五个初步有效特征层。

然后第二部分是加强特征提取部分，主要利用的是从主干部分获取到的五个有效特征层，
然后分别对其进行上采样，并且进行特征融合，这里的融合采用的是concat操作进行堆叠，
因为堆叠时需要保证两者的形状一致，因此这里要进行两倍的上采样操作，以获得相同的宽高，
之后才进行堆叠，获得一个最终的，融合了所有特征的有效特征层。

以上两个部分看起来是左右两边完全对称，并形成了一个U形，现在到了最后一个部分，
我们利用最终获得的最后一个有效特征层对每一个特征点进行分类，相当于对每一个像素点进行分类。
进行分类之前先通过1x1卷积进行通道调整，将最终特征层的通道数调整成num_classes。

损失函数loss由两个部分组成：Cross Entropy Loss和Dice Loss。
Cross Entropy Loss就是普通的交叉熵损失，当语义分割平台利用Softmax对像素点进行分类的时候，进行使用。
Dice loss将语义分割的评价指标作为Loss，Dice系数是一种集合相似度度量函数，通常用于计算两个样本的相似度，取值范围在[0,1]。

# fcn（2015）
fcn也叫全卷积网络，将传统卷积网络后面的全连接层换成了卷积层，这样一来可以减少运算量，因为全连接层的运算十分巨大
二是去除了全连接层，因此可以适应不同大小的输入。
在上采样部分，用反卷积(deconv)层进行增大数据尺寸，然后在跳跃连接部分采用了直接相加add操作，使用跳级结构提升精确性
这里有分多个阶段，分别叫FCN-8s、FCN-16s、FCN-32s，
跳级结构利用浅层信息辅助逐步升采样，有更精细的结果，其中FCN-8s分割得结果较为精细。
在经过反卷积以及跳跃连接步骤中，使它恢复到输入图像相同的尺寸，
从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息
最后在上采样的特征图上进行逐像素分类

# pspnet（2016）
pspnet提出了金字塔池化模块，能够聚合不同区域的上下文信息，从而提高获取全局信息的能力。
psp结构是将获取到特征层划分为不同大小：6x6，3x3，2x2，1x1的网格，然后对每个网格分别进行内部的平均池化
实现聚合不同区域的上下文信息，从而提高获取全局信息的能力。
主干特征提取网络依旧是通过卷积等操作获取到一个基本的特征层，这里的卷积采用了空洞卷积来增大感受野，
然后提供给之后的特征加强网络，在特征加强网络中，首先将获取到的特征层进行不同大小的划分 
在PSP结构典型情况下，会将输入进来的特征层划分成6x6，3x3，2x2，1x1的区域，然后每个区域内部各自进行平均池化。
假设PSP结构输入进来的特征层为30x30x320，此时这个特征层的高和宽均为30，
这里的平均池化相当于将特征层划分成6x6的区域，每个区域内部各自进行平均池化。
最后再concat堆叠起来做预测
预测部分包括首先利用一个3x3卷积对特征进行整合；
然后利用一个1x1卷积进行通道调整，调整成与输出类别一样大小；
最后利用resize进行上采样使得最终输出层，宽高和输入图片一样。

损失函数loss由两个部分组成：Cross Entropy Loss和Dice Loss。
Cross Entropy Loss就是普通的交叉熵损失，当语义分割平台利用Softmax对像素点进行分类的时候，进行使用。
Dice loss将语义分割的评价指标作为Loss，Dice系数是一种集合相似度度量函数，通常用于计算两个样本的相似度，取值范围在[0,1]。
dice就是将预测结果和真实结果的交乘上2，除上预测结果加上真实结果。
其值在0-1之间。越大表示预测结果和真实结果重合度越大。所以Dice系数是越大越好。
如果作为LOSS的话是越小越好，所以使得Dice loss = 1 - Dice，就可以将Loss作为语义分割的损失了。

# Mask R-CNN（2016）
Mask R-CNN使用resnet101作为主干特征提取网络，然后通过fpn网络获取P2、P3、P4、P5、P65个有效特征层
这里是为了下面的RPN网络提供有效特征层，对先验框进行解码获得建议框

上述提到的P2、P3、P4、P5可以作为Classifier和Mask网络的有效特征层
利用Classifier预测框网络对有效特征层进行下一步的操作，对建议框解码获得最终预测框；
利用Mask语义分割网络对有效特征层进行下一步的操作，获得每一个预测框内部的语义分割结果。

在进行建议框获取时，使用同一个RPN建议框获取先验框调整参数以及先验框内部是否包含物体
也就是分别进行一次anchors_per_location x 4的卷积 和一次anchors_per_location x 2的卷积。

anchors_per_location x 4的卷积 用于预测 公用特征层上 每一个网格点上 每一个先验框的变化情况。
因为预测结果需要结合先验框获得预测框，预测结果就是先验框的变化情况。
anchors_per_location x 2的卷积 用于预测 公用特征层上 每一个网格点上 每一个预测框内部是否包含了物体。

然后根据建议框对之前的多个特征层进行截取，建议框就是对图片哪一个区域有物体存在进行初步筛选，
筛选之后进行截取，截取后的内容会resize成7x7x256的大小。
需要注意的是，要找到建议框属于那个特征层，这个要从建议框的大小进行判断。

之后就进行解码：
取出不属于背景，并且得分大于指定阈值的建议框。
利用建议框和classifier模型的预测结果进行解码，获得最终预测框的位置。
利用得分和最终预测框的位置进行非极大抑制，防止重复检测。

通过建议框以及上述处理，得到更加准确的预测框，
可以利用这个预测框对mask模型中用到的公用特征层进行截取，
截取后，利用mask模型再对像素点进行分类，获得语义分割结果




传统的yolo都是使用同一个特征图来进行分类和回归的，而yolox这次将三个分类head进行解耦，因为觉得两者是有冲突的，
于是就分别进行回归与分类，解耦之后，不仅加快了收敛，而且精度也上升了。
并且由于在如今anchor free的盛行之下，yolox也采用了anchor free。
一是可以不需要进行聚类来得到anchor，二是减少了检测头的复杂度。

# 网络结构：
主要使用了BaseConv，也就是conv+batchnormal+silu；然后还使用了focus结构，和yolov5中的一致，
目的是融合信息并且不增加额外的计算量。
以及使用了SPPBottleneck，目的是将不同尺度的特征图缩放成固定大小，方便后面处理。
backbone上仍是使用了darknet53，dark3,dark4,dark5为三个输出特征层，用于后面的neck层，YOLOPAFPN，加强特征的提取
Path Aggregation Network (PANet)实际是对Mask RCNN上进行做多处改进，来加强特征融合，比
如引入bottom-up path augmentation结构，充分利用网络浅特征进行分割；
以及adaptive feature pooling使得提取到的ROI特征更加丰富；
引入fully-connected fusion，通过融合一个前背景二分类支路的输出得到更加精确的分割结果。
整体而言对于目标检测和分割系列算法有不少启发
到了head层，就和上面所说的一样，进行解耦操作，分开了回归与分类的过程。

# 数据增强
这里着重使用了mixyo与mosaic进行数据增强。
mosaic数据增强对四张图片进行不同形式的处理与拼接，
并且每一张图片都有其对应的区域面积，将四张图片进行拼接后就获得了一张新的图片，
这样就相当于一下子传入了四张图片给网络了，这样也极大丰富了检测物体的背景，并且在标准化BN计算的时候也会同时计算四张图片的数据。

mixup就是将两张图进行不同权重的分配，最后叠加起来，有点重影的感觉在里头。

注意的是，1.在训练的最后15个epoch，这两个数据增强会被关闭掉。
2.由于采取了更强的数据增强方式，所以ImageNet预训练将毫无意义，因此，所有的模型，均是从头开始训练的。

# simOTA与multi positive
传统的anchor-free版本仅仅对每个目标赋予一个正样本，而忽视了其他高质量预测。
因此这里为每个中心点赋予了多个正样本。并且为每个gt分配不同数量的anchor。
分配策略可以理解为，根据不同anchor的模糊程度赋予不同的权重，从而得到分配的数量

# 损失函数
定位损失是用来iou或者giou损失，两者选其一
前景背景损失和类别损失则是采用BCE_loss
这里的iou_loss和cls_loss，只针对目标框和筛选出的正样本预测框进行计算。而obj_loss，则还是针对8400个预测框。